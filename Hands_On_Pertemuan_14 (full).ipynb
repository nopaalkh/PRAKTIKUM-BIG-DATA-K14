{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2a030e3",
      "metadata": {
        "id": "e2a030e3"
      },
      "source": [
        "# Hands-On Pertemuan 14: Advanced Machine Learning using Spark MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099562db",
      "metadata": {
        "id": "099562db"
      },
      "source": [
        "## Objectives:\n",
        "- Understand and implement advanced machine learning tasks using Spark MLlib.\n",
        "- Build and evaluate models using real-world datasets.\n",
        "- Explore techniques like feature engineering and hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77df771a",
      "metadata": {
        "id": "77df771a"
      },
      "source": [
        "## Introduction to Spark MLlib\n",
        "Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ae225b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9ae225b",
        "outputId": "5a682df1-4467-4d7f-de86-6e1abfce85a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b266267",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b266267",
        "outputId": "56ef8a0e-5df8-4f22-e727-850c3246cc28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Intercept: 11.56891272665312\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Example dataset\n",
        "data = [(1, [2.0, 3.0], 0), (2, [1.0, 5.0], 1), (3, [2.5, 4.5], 1), (4, [3.0, 6.0], 0)]\n",
        "columns = ['ID', 'Features', 'Label']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Convert the 'Features' array into individual columns\n",
        "df = df.withColumn('Feature1', F.col('Features')[0]) \\\n",
        "       .withColumn('Feature2', F.col('Features')[1])\n",
        "\n",
        "# Use VectorAssembler to combine 'Feature1' and 'Feature2' into a single vector\n",
        "assembler = VectorAssembler(inputCols=['Feature1', 'Feature2'], outputCol='FeaturesVec')\n",
        "df_vector = assembler.transform(df)\n",
        "\n",
        "# Train logistic regression model\n",
        "lr = LogisticRegression(featuresCol='FeaturesVec', labelCol='Label')\n",
        "model = lr.fit(df_vector)\n",
        "\n",
        "# Display coefficients and intercept\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9066e04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9066e04",
        "outputId": "ead1dc20-c2cd-452a-a0a9-6e753fbd0a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers: [array([5.33333333, 5.33333333]), array([15., 15.])]\n"
          ]
        }
      ],
      "source": [
        "# Practice: KMeans Clustering\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Example dataset\n",
        "data = [(1, [1.0, 1.0]), (2, [5.0, 5.0]), (3, [10.0, 10.0]), (4, [15.0, 15.0])]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Confert\n",
        "df = df.withColumn('Feature1', F.col('Features')[0]) \\\n",
        "       .withColumn('Feature2', F.col('Features')[1])\n",
        "\n",
        "# VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=['Feature1', 'Feature2'], outputCol='FeaturesVec')\n",
        "df_vector = assembler.transform(df)\n",
        "\n",
        "# Train KMeans clustering model\n",
        "kmeans = KMeans(featuresCol='FeaturesVec', k=2)\n",
        "model = kmeans.fit(df_vector)\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60a8d7e",
      "metadata": {
        "id": "a60a8d7e"
      },
      "source": [
        "## Homework\n",
        "- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n",
        "- Build a classification model using Spark MLlib and evaluate its performance.\n",
        "- Explore hyperparameter tuning using cross-validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning : Linear Regression**"
      ],
      "metadata": {
        "id": "CnOVsizPXsBY"
      },
      "id": "CnOVsizPXsBY"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "\n",
        "# Step 1: Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LinearRegressionWithStrings\").getOrCreate()\n",
        "\n",
        "# Step 2: Load Dataset\n",
        "file_path = \"/content/youtube.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Explore Dataset\n",
        "df.printSchema()\n",
        "print(\"Available Columns: \", df.columns)\n",
        "\n",
        "# Step 4: Konversi Kolom Non-Numerik\n",
        "string_columns = [\n",
        "    'video_id', 'trending_date', 'title', 'channel_title',\n",
        "    'publish_date', 'time_frame', 'published_day_of_week',\n",
        "    'publish_country', 'tags'\n",
        "]\n",
        "\n",
        "# Ubah setiap kolom string menjadi indeks numerik\n",
        "for col in string_columns:\n",
        "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_Index\")\n",
        "    df = indexer.fit(df).transform(df)\n",
        "\n",
        "# Step 5: Tentukan Target dan Fitur\n",
        "# Ganti nama kolom 'views' sebagai target (atau gunakan yang relevan)\n",
        "label_column = 'views'  # Ganti ini dengan kolom target yang benar\n",
        "feature_columns = [col for col in df.columns if col != label_column and col not in string_columns]\n",
        "\n",
        "# Pastikan target kolom ada dalam dataset\n",
        "if label_column not in df.columns:\n",
        "    raise ValueError(f\"Kolom target '{label_column}' tidak ditemukan dalam dataset. Kolom yang tersedia: {df.columns}\")\n",
        "\n",
        "# Gabungkan fitur ke dalam satu vektor\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol='Features')\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Step 6: Split Dataset\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 7: Train Linear Regression Model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol=label_column)\n",
        "model = lr.fit(train_df)\n",
        "\n",
        "# Step 8: Evaluate Model\n",
        "test_results = model.evaluate(test_df)\n",
        "\n",
        "print(f\"RMSE: {test_results.rootMeanSquaredError}\")\n",
        "print(f\"R2: {test_results.r2}\")\n",
        "print(f\"Coefficients: {model.coefficients}\")\n",
        "print(f\"Intercept: {model.intercept}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5fGYpIdJEcY",
        "outputId": "2256be9f-8aef-41bf-8cb9-8e2f2e11c6f5"
      },
      "id": "E5fGYpIdJEcY",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- index: integer (nullable = true)\n",
            " |-- video_id: string (nullable = true)\n",
            " |-- trending_date: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- channel_title: string (nullable = true)\n",
            " |-- category_id: integer (nullable = true)\n",
            " |-- publish_date: string (nullable = true)\n",
            " |-- time_frame: string (nullable = true)\n",
            " |-- published_day_of_week: string (nullable = true)\n",
            " |-- publish_country: string (nullable = true)\n",
            " |-- tags: string (nullable = true)\n",
            " |-- views: integer (nullable = true)\n",
            " |-- likes: integer (nullable = true)\n",
            " |-- dislikes: integer (nullable = true)\n",
            " |-- comment_count: integer (nullable = true)\n",
            " |-- comments_disabled: boolean (nullable = true)\n",
            " |-- ratings_disabled: boolean (nullable = true)\n",
            " |-- video_error_or_removed: boolean (nullable = true)\n",
            "\n",
            "Available Columns:  ['index', 'video_id', 'trending_date', 'title', 'channel_title', 'category_id', 'publish_date', 'time_frame', 'published_day_of_week', 'publish_country', 'tags', 'views', 'likes', 'dislikes', 'comment_count', 'comments_disabled', 'ratings_disabled', 'video_error_or_removed']\n",
            "RMSE: 5504076.336269728\n",
            "R2: 0.7060624565333866\n",
            "Coefficients: [-3.521053892389928,13723.31066411285,51.99844108530883,129.81496228252215,-201.55257102319288,415651.4106044654,2611080.7004925893,41932.06022571163,1.0789424627682223,4026.077216032239,4.563302381575788,25.818839797032876,-1394.3517610441183,33911.26044435794,15852.468953306401,285514.5820768947,-0.9600123184074643]\n",
            "Intercept: -1155460.540264824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning : Logistic Regression**"
      ],
      "metadata": {
        "id": "Y7oS0odgX5G-"
      },
      "id": "Y7oS0odgX5G-"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Step 1: Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LogisticRegressionWithBooleans\").getOrCreate()\n",
        "\n",
        "# Step 2: Load Dataset\n",
        "file_path = \"/content/youtube.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Explore Dataset\n",
        "df.printSchema()\n",
        "print(\"Available Columns: \", df.columns)\n",
        "\n",
        "# Step 4: Konversi Kolom Non-Numerik\n",
        "string_columns = [\n",
        "    'video_id', 'trending_date', 'title', 'channel_title',\n",
        "    'publish_date', 'time_frame', 'published_day_of_week',\n",
        "    'publish_country', 'tags'\n",
        "]\n",
        "\n",
        "# Ubah setiap kolom string menjadi indeks numerik\n",
        "for col_name in string_columns:\n",
        "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_Index\")\n",
        "    df = indexer.fit(df).transform(df)\n",
        "\n",
        "# Step 5: Konversi Kolom Boolean\n",
        "# Ubah kolom ratings_disabled dari Boolean menjadi Integer\n",
        "df = df.withColumn('ratings_disabled_Int', col('ratings_disabled').cast('integer'))\n",
        "\n",
        "# Step 6: Tentukan Target dan Fitur\n",
        "label_column = 'ratings_disabled_Int'  # Menggunakan kolom boolean yang dikonversi\n",
        "\n",
        "# Pilih fitur numerik dan vektorize\n",
        "feature_columns = ['views', 'likes', 'dislikes', 'comment_count']  # Pastikan kolom ini ada di dataset\n",
        "indexed_columns = [f\"{col_name}_Index\" for col_name in string_columns]\n",
        "all_features = feature_columns + indexed_columns\n",
        "\n",
        "assembler = VectorAssembler(inputCols=all_features, outputCol='FeaturesVec')\n",
        "df_vector = assembler.transform(df)\n",
        "\n",
        "# Step 7: Split Dataset\n",
        "train_df, test_df = df_vector.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 8: Train Logistic Regression Model\n",
        "lr = LogisticRegression(featuresCol='FeaturesVec', labelCol=label_column, maxIter=10)\n",
        "model = lr.fit(train_df)\n",
        "\n",
        "# Step 9: Evaluate Model\n",
        "train_summary = model.summary\n",
        "print(f\"Accuracy: {train_summary.accuracy}\")\n",
        "print(f\"F1 Score: {train_summary.fMeasureByLabel()}\")\n",
        "print(f\"Precision: {train_summary.precisionByLabel}\")\n",
        "print(f\"Recall: {train_summary.recallByLabel}\")\n",
        "\n",
        "# Step 10: Make Predictions\n",
        "predictions = model.transform(test_df)\n",
        "predictions.select('video_id', 'FeaturesVec', 'prediction', label_column).show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VW5Y9QmOdT-",
        "outputId": "52258f8f-ed82-411a-d211-c1e75d10eb25"
      },
      "id": "3VW5Y9QmOdT-",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- index: integer (nullable = true)\n",
            " |-- video_id: string (nullable = true)\n",
            " |-- trending_date: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- channel_title: string (nullable = true)\n",
            " |-- category_id: integer (nullable = true)\n",
            " |-- publish_date: string (nullable = true)\n",
            " |-- time_frame: string (nullable = true)\n",
            " |-- published_day_of_week: string (nullable = true)\n",
            " |-- publish_country: string (nullable = true)\n",
            " |-- tags: string (nullable = true)\n",
            " |-- views: integer (nullable = true)\n",
            " |-- likes: integer (nullable = true)\n",
            " |-- dislikes: integer (nullable = true)\n",
            " |-- comment_count: integer (nullable = true)\n",
            " |-- comments_disabled: boolean (nullable = true)\n",
            " |-- ratings_disabled: boolean (nullable = true)\n",
            " |-- video_error_or_removed: boolean (nullable = true)\n",
            "\n",
            "Available Columns:  ['index', 'video_id', 'trending_date', 'title', 'channel_title', 'category_id', 'publish_date', 'time_frame', 'published_day_of_week', 'publish_country', 'tags', 'views', 'likes', 'dislikes', 'comment_count', 'comments_disabled', 'ratings_disabled', 'video_error_or_removed']\n",
            "Accuracy: 0.9913865220759102\n",
            "F1 Score: [0.9956729497097142, 0.08250825082508251]\n",
            "Precision: [0.9917136279426698, 0.5376344086021505]\n",
            "Recall: [0.9996640126268743, 0.044682752457551385]\n",
            "+-----------+--------------------+----------+--------------------+\n",
            "|   video_id|         FeaturesVec|prediction|ratings_disabled_Int|\n",
            "+-----------+--------------------+----------+--------------------+\n",
            "|5qpjK5DgCt4|[3191434.0,146033...|       0.0|                   0|\n",
            "|39idVpFF7NQ|[2103417.0,15993....|       0.0|                   0|\n",
            "|jr9QtXwC9vc|[826059.0,3543.0,...|       0.0|                   0|\n",
            "|GgVmn66oK_A|[544770.0,7848.0,...|       0.0|                   0|\n",
            "|B5HORANmzHw|[223871.0,8421.0,...|       0.0|                   0|\n",
            "|JBZTZZAcFTw|[145921.0,1707.0,...|       0.0|                   0|\n",
            "|n30k5CwLhS4|[50867.0,715.0,23...|       0.0|                   0|\n",
            "|0mlNzVSJrT0|[98966.0,2486.0,1...|       0.0|                   0|\n",
            "|BWPrk9PUwQE|[1456472.0,33505....|       0.0|                   0|\n",
            "|ogYum4kWXgk|[69844.0,3417.0,3...|       0.0|                   0|\n",
            "+-----------+--------------------+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KMeans Clustering**"
      ],
      "metadata": {
        "id": "_rVY8gKrX-eM"
      },
      "id": "_rVY8gKrX-eM"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "\n",
        "# Step 1: Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"KMeansWithStrings\").getOrCreate()\n",
        "\n",
        "# Step 2: Load Dataset\n",
        "file_path = \"/content/youtube.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Explore Dataset\n",
        "df.printSchema()\n",
        "print(\"Available Columns: \", df.columns)\n",
        "\n",
        "# Step 4: Konversi Kolom Non-Numerik\n",
        "string_columns = [\n",
        "    'video_id', 'trending_date', 'title', 'channel_title',\n",
        "    'publish_date', 'time_frame', 'published_day_of_week',\n",
        "    'publish_country', 'tags'\n",
        "]\n",
        "\n",
        "# Ubah setiap kolom string menjadi indeks numerik\n",
        "for col in string_columns:\n",
        "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_Index\")\n",
        "    df = indexer.fit(df).transform(df)\n",
        "\n",
        "# Step 5: Pilih Fitur\n",
        "# Pilih beberapa kolom numerik untuk clustering, seperti 'views', 'likes', dll.\n",
        "feature_columns = ['views', 'likes', 'dislikes', 'comment_count']  # Pastikan kolom ini ada di dataset\n",
        "indexed_columns = [f\"{col}_Index\" for col in string_columns]\n",
        "all_features = feature_columns + indexed_columns\n",
        "\n",
        "# Gabungkan fitur menjadi satu vektor\n",
        "assembler = VectorAssembler(inputCols=all_features, outputCol='FeaturesVec')\n",
        "df_vector = assembler.transform(df)\n",
        "\n",
        "# Step 6: Train KMeans Model\n",
        "kmeans = KMeans(featuresCol='FeaturesVec', k=3, seed=42)  # k=3 untuk 3 cluster, sesuaikan dengan kebutuhan\n",
        "model = kmeans.fit(df_vector)\n",
        "\n",
        "# Step 7: Evaluate Model\n",
        "centers = model.clusterCenters()\n",
        "print(f\"Cluster Centers: {centers}\")\n",
        "\n",
        "# Step 8: Assign Clusters to Data\n",
        "df_clustered = model.transform(df_vector)\n",
        "df_clustered.select('video_id', 'FeaturesVec', 'prediction').show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY2vGVHXJFJf",
        "outputId": "dbf7e2fc-f6da-44c9-f5a1-2fa57014c9b6"
      },
      "id": "ZY2vGVHXJFJf",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- index: integer (nullable = true)\n",
            " |-- video_id: string (nullable = true)\n",
            " |-- trending_date: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- channel_title: string (nullable = true)\n",
            " |-- category_id: integer (nullable = true)\n",
            " |-- publish_date: string (nullable = true)\n",
            " |-- time_frame: string (nullable = true)\n",
            " |-- published_day_of_week: string (nullable = true)\n",
            " |-- publish_country: string (nullable = true)\n",
            " |-- tags: string (nullable = true)\n",
            " |-- views: integer (nullable = true)\n",
            " |-- likes: integer (nullable = true)\n",
            " |-- dislikes: integer (nullable = true)\n",
            " |-- comment_count: integer (nullable = true)\n",
            " |-- comments_disabled: boolean (nullable = true)\n",
            " |-- ratings_disabled: boolean (nullable = true)\n",
            " |-- video_error_or_removed: boolean (nullable = true)\n",
            "\n",
            "Available Columns:  ['index', 'video_id', 'trending_date', 'title', 'channel_title', 'category_id', 'publish_date', 'time_frame', 'published_day_of_week', 'publish_country', 'tags', 'views', 'likes', 'dislikes', 'comment_count', 'comments_disabled', 'ratings_disabled', 'video_error_or_removed']\n",
            "Cluster Centers: [array([5.11547980e+07, 1.04403808e+06, 7.16654740e+04, 1.11267734e+05,\n",
            "       3.56570794e+02, 1.25578340e+02, 3.69101642e+02, 4.86896138e+02,\n",
            "       7.10275189e+01, 1.04167776e+01, 1.70395029e+00, 2.27607634e+00,\n",
            "       9.94558810e+02]), array([1.46380366e+06, 4.80058738e+04, 2.17443320e+03, 5.23170794e+03,\n",
            "       1.29444371e+04, 1.00543312e+02, 1.33743186e+04, 1.55918642e+03,\n",
            "       9.13591284e+01, 7.85768820e+00, 2.67352368e+00, 1.46778819e+00,\n",
            "       1.10302458e+04]), array([2.06389665e+08, 2.97972133e+06, 2.72154831e+05, 2.58169483e+05,\n",
            "       1.58695652e+02, 1.35531401e+02, 1.62768116e+02, 5.38850242e+02,\n",
            "       7.70772947e+01, 1.07198068e+01, 2.29468599e+00, 2.68599034e+00,\n",
            "       2.82338164e+02])]\n",
            "+-----------+--------------------+----------+\n",
            "|   video_id|         FeaturesVec|prediction|\n",
            "+-----------+--------------------+----------+\n",
            "|2kyS6SvSYSE|[748374.0,57527.0...|         1|\n",
            "|1ZAPwfrtAFY|[2418783.0,97185....|         1|\n",
            "|5qpjK5DgCt4|[3191434.0,146033...|         1|\n",
            "|puqaWrEC7tY|[343168.0,10172.0...|         1|\n",
            "|d380meD0W0M|[2095731.0,132235...|         1|\n",
            "|gHZ1Qz0KiKM|[119180.0,9763.0,...|         1|\n",
            "|39idVpFF7NQ|[2103417.0,15993....|         1|\n",
            "|nc99ccSXST0|[817732.0,23663.0...|         1|\n",
            "|jr9QtXwC9vc|[826059.0,3543.0,...|         1|\n",
            "|TUmyygCMMGA|[256426.0,12654.0...|         1|\n",
            "+-----------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter tuning using cross-validation.**"
      ],
      "metadata": {
        "id": "dh7dKMr0YIL_"
      },
      "id": "dh7dKMr0YIL_"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Step 1: Definisikan evaluator untuk binary classification\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=label_column)\n",
        "\n",
        "# Step 2: Buat grid parameter untuk hyperparameter tuning\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(lr.regParam, [0.01, 0.1, 0.5])  # Regularization parameter\n",
        "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])  # ElasticNet parameter\n",
        "             .addGrid(lr.maxIter, [10, 20, 30])  # Iterasi model\n",
        "             .build())\n",
        "\n",
        "# Step 3: Setup CrossValidator\n",
        "crossval = CrossValidator(estimator=lr,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)  # 3-fold cross-validation\n",
        "\n",
        "# Step 4: Latih model dengan cross-validation\n",
        "cvModel = crossval.fit(train_df)\n",
        "\n",
        "# Step 5: Evaluasi Model\n",
        "cvPredictions = cvModel.transform(test_df)\n",
        "print(f\"Accuracy of the model: {evaluator.evaluate(cvPredictions)}\")\n",
        "\n",
        "# Step 6: Tampilkan parameter terbaik\n",
        "bestModel = cvModel.bestModel\n",
        "print(f\"Best Model Parameters: {bestModel.extractParamMap()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zZ2GZUjNGL9",
        "outputId": "651344ea-ee08-489a-b85a-6f5e279348f4"
      },
      "id": "0zZ2GZUjNGL9",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 0.7545396773459662\n",
            "Best Model Parameters: {Param(parent='LogisticRegression_a90051a2aaf5', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2, Param(parent='LogisticRegression_a90051a2aaf5', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_a90051a2aaf5', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto', Param(parent='LogisticRegression_a90051a2aaf5', name='featuresCol', doc='features column name.'): 'FeaturesVec', Param(parent='LogisticRegression_a90051a2aaf5', name='fitIntercept', doc='whether to fit an intercept term.'): True, Param(parent='LogisticRegression_a90051a2aaf5', name='labelCol', doc='label column name.'): 'ratings_disabled_Int', Param(parent='LogisticRegression_a90051a2aaf5', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0, Param(parent='LogisticRegression_a90051a2aaf5', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='LogisticRegression_a90051a2aaf5', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='LogisticRegression_a90051a2aaf5', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='LogisticRegression_a90051a2aaf5', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='LogisticRegression_a90051a2aaf5', name='regParam', doc='regularization parameter (>= 0).'): 0.01, Param(parent='LogisticRegression_a90051a2aaf5', name='standardization', doc='whether to standardize the training features before fitting the model.'): True, Param(parent='LogisticRegression_a90051a2aaf5', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5, Param(parent='LogisticRegression_a90051a2aaf5', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GbsyFIMEUlkA"
      },
      "id": "GbsyFIMEUlkA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}